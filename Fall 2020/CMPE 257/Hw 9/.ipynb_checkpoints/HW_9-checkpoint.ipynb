{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dadAJEp9wc0d"
   },
   "outputs": [],
   "source": [
    "# Q1: Demo matrices - 1 point\n",
    "\n",
    "# Assuming a Stride of 1, the Output matrix will be:\n",
    "# 4 3 4\n",
    "# 2 4 3\n",
    "# 2 3 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lanYgQqZ09EG"
   },
   "source": [
    "Calculate the output:\n",
    "\n",
    "Image:\n",
    "\n",
    "1 1 1 0 0\n",
    "\n",
    "0 1 1 1 0\n",
    "\n",
    "0 0 1 1 1\n",
    "\n",
    "0 0 1 1 0\n",
    "\n",
    "0 1 1 0 0\n",
    "\n",
    "\n",
    "Filter:\n",
    "\n",
    "1 0 1\n",
    "\n",
    "0 1 0\n",
    "\n",
    "1 0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jZkrCg5b1IHk"
   },
   "outputs": [],
   "source": [
    "#Q2: What are the advantages of a CNN over a fully connected DNN for image classification? - 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- They are able to capture and learn relevant features from an image at different levels while a DNN cannot (feature learning)\n",
    "- CNN networks can be less complex than DNN through the use of filters and weight sharing: each neuron does not need to be fully connected\n",
    "- This lowering of neuron connections allow the CNN to be trained much faster than a DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPDL4oYRxFDC"
   },
   "outputs": [],
   "source": [
    "#Q3: If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem? - 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1) Try to rescale the images down in size so that they don't take up that much memory\n",
    "- 2) Lower the batch size for training so that fewer images are trained during each batch\n",
    "- 3) Decrease the number of layers within the CNN itself so that fewer parameters are being used\n",
    "- 4) Use Pooling layers within the network to downsample the image to a smaller size\n",
    "- 5) Buy a better GPU :) - Kidding - Adjust the filter output size so that it's smaller than the current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "hNftAEsdxMMQ"
   },
   "outputs": [],
   "source": [
    "#Q4: Use the dataset: https://www.tensorflow.org/datasets/catalog/citrus_leaves - 1 point\n",
    "# Using the Cifar10 dataset since citrus leaves has been not working\n",
    "import tensorflow as tf\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "#Q5: Split it into a training set, and a test set. - 1 point\n",
    "# Above dataset is already loaded as train and test data with 50,000 images for train\n",
    "# and 10,000 for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ozhxqfTkxU4T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                108170    \n",
      "=================================================================\n",
      "Total params: 127,562\n",
      "Trainable params: 127,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q6: Build a CNN model - 3 points\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "# Adding a 2D convolution layer and specifying the input shape of the matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# Max pool layer for downsizing and specifying size of output\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Another layer - specifying neuron size and matrix output\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Flattening 3D image down to 1D for classification\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "# Adding dense layer as final output for classes\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Adam optimizer for fast training and SparseCatCross for image loss calculation\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Credit to: https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 2.2286 - accuracy: 0.3204 - val_loss: 1.5778 - val_accuracy: 0.4322\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4369 - accuracy: 0.4932 - val_loss: 1.4633 - val_accuracy: 0.4816\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.2720 - accuracy: 0.5600 - val_loss: 1.3106 - val_accuracy: 0.5440\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1061 - accuracy: 0.6180 - val_loss: 1.2950 - val_accuracy: 0.5608\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 28s 20ms/step - loss: 0.9915 - accuracy: 0.6602 - val_loss: 1.3333 - val_accuracy: 0.5762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9cdf1a2790>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3863 - accuracy: 0.5672\n",
      "Model accuracy:  0.5672000050544739\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print(\"Model accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mWCCCfgmxY45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 271,242\n",
      "Trainable params: 270,730\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q7: Fine-tune it and learn its accuracy. Bring the minimum accuracy of 85%. Jot down any challenges/issues you face during this process. - 3 points\n",
    "\n",
    "model = models.Sequential()\n",
    "# Adding a 2D convolution layer and specifying the input shape of the matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# Max pool layer for downsizing and specifying size of output\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Another layer - specifying neuron size and matrix output\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Flattening 3D image down to 1D for classification\n",
    "model.add(layers.Flatten())\n",
    "# Adding hidden dense layer before output layer\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Adding dense layer as final output for classes\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()\n",
    "# Adam optimizer for fast training and SparseCatCross for image loss calculation\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 113s 80ms/step - loss: 1.5040 - accuracy: 0.4610 - val_loss: 1.3649 - val_accuracy: 0.5196\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 126s 90ms/step - loss: 1.1381 - accuracy: 0.5966 - val_loss: 1.3263 - val_accuracy: 0.5520\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 123s 88ms/step - loss: 0.9636 - accuracy: 0.6618 - val_loss: 1.0933 - val_accuracy: 0.6222\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 122s 87ms/step - loss: 0.8478 - accuracy: 0.7015 - val_loss: 1.1155 - val_accuracy: 0.6278\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 118s 84ms/step - loss: 0.7623 - accuracy: 0.7339 - val_loss: 1.2016 - val_accuracy: 0.6106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9cce478e20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 21ms/step - loss: 1.2183 - accuracy: 0.6051\n",
      "Model accuracy:  0.6050999760627747\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print(\"Model accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges/Process to 85%\n",
    "- First iteration was base model at Q6. Accuracy was low for training and even lower for testing (56%). Attempt to add more convolution layers and train for more epochs\n",
    "- Second attempt was slightly better by adding two more convolution layers to model. Test accuracy at 60%. Will try adding dense layer after the flatten\n",
    "- Adding extra dense layer actually made accuracy drop to 58%. Going to normalize the data to between 0 and 1 and add more convolution layers to model. Also running for 15 epochs now.\n",
    "- Running at 15 epochs did help in raising accuracy to 67% along with more covolution layers and the normalizing. Now adding BatchNormalization layers to model so that the feature space be kept tight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak5lAXKuzKzG"
   },
   "source": [
    "Useful reading: \n",
    "*   https://www.tensorflow.org/tutorials/generative/style_transfer\n",
    "\n",
    "*   https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
