{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAIYjjuMd_KM"
   },
   "source": [
    "### Please follow the instructions given in the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5I9eGsDLeDkz"
   },
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fz4MR-mAeFhw"
   },
   "outputs": [],
   "source": [
    "#Import XGBoost, Pandas, and sklearn for the function that we will use to calculate the accuracy. \n",
    "#The accuracy is required to understand how our model is performing.\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "avgD9WNheIDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Channel  Region  Fresh   Milk  Grocery  Frozen  Detergents_Paper  \\\n",
      "0          2       3  12669   9656     7561     214              2674   \n",
      "1          2       3   7057   9810     9568    1762              3293   \n",
      "2          2       3   6353   8808     7684    2405              3516   \n",
      "3          1       3  13265   1196     4221    6404               507   \n",
      "4          2       3  22615   5410     7198    3915              1777   \n",
      "..       ...     ...    ...    ...      ...     ...               ...   \n",
      "435        1       3  29703  12051    16027   13135               182   \n",
      "436        1       3  39228   1431      764    4510                93   \n",
      "437        2       3  14531  15488    30243     437             14841   \n",
      "438        1       3  10290   1981     2232    1038               168   \n",
      "439        1       3   2787   1698     2510      65               477   \n",
      "\n",
      "     Delicassen  \n",
      "0          1338  \n",
      "1          1776  \n",
      "2          7844  \n",
      "3          1788  \n",
      "4          5185  \n",
      "..          ...  \n",
      "435        2204  \n",
      "436        2346  \n",
      "437        1867  \n",
      "438        2125  \n",
      "439          52  \n",
      "\n",
      "[440 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import the wholesale customer dataset - 1 point\n",
    "\n",
    "# Import needed libraries to get data from URL and load into Pandas DF\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "# Define url and OS path that I want to save csv data under\n",
    "DATA_URL = \"https://raw.githubusercontent.com/JacobBRodriguez/SJSU/master/Fall%202020/DataSets/wholesale-data.csv\"\n",
    "DATA_PATH = os.path.join(\"/Users/Do-While/Desktop/SJSU/Classes/SJSU/Fall 2020\", \"DataSets\")\n",
    "\n",
    "# Function to get data from URL and return it as Pandas dataframe\n",
    "def fetch_and_load_from_url(data_url, data_path):\n",
    "    \n",
    "    # If no data path exists, create directory\n",
    "    if not os.path.isdir(DATA_PATH):\n",
    "        os.makedirs(DATA_PATH)\n",
    "    # create text document path under OS path\n",
    "    txt_path = os.path.join(DATA_PATH, \"hw6_data.txt\")\n",
    "    # Using URL, request data and return to created path\n",
    "    urllib.request.urlretrieve(DATA_URL, txt_path)\n",
    "    # Read in text file, convert csv to pandas df and return upon close of file\n",
    "    with open(txt_path, \"r\") as file:\n",
    "        return pd.read_csv(file, dtype='Int64')\n",
    "    \n",
    "hwDataSet = fetch_and_load_from_url(DATA_URL, DATA_PATH)\n",
    "print(hwDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7UW6TgjjeQhP"
   },
   "outputs": [],
   "source": [
    "#Create training and test sets - 80:20 - 1 point\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_df = hwDataSet.copy()\n",
    "# Divide data into X and Y - with Channel being our Target variable as specified later in hw\n",
    "x_data = new_df.iloc[:,1:]\n",
    "y_data = new_df.iloc[:,0]\n",
    "\n",
    "# Split data into train and test - 80/20 split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.20, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gDfMIZc7fGL_"
   },
   "outputs": [],
   "source": [
    "#Convert the pandas dataframe into a DMatrix, an internal data structure that is used by XGBoost to store training and testing datasets.\n",
    "# - 2 points\n",
    "\n",
    "# Get the x data values and keep the y labeled data as is for functional transformation\n",
    "dtrain = xgb.DMatrix(data=x_train.values, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GvJv3uAEfLP2"
   },
   "outputs": [],
   "source": [
    "#Specify the training parameters and train the model. - 4 points\n",
    "\n",
    "# Max depth of a given tree is capped at 3\n",
    "param = {'max_depth': 3}\n",
    "# Managing the learning rate by setting the feature weights impact on future boosting steps\n",
    "param[\"eta\"] = 0.6\n",
    "# Minimum loss reduction required to make more partitions of leaf nodes of tree. Higher being more conservative\n",
    "param[\"gamma\"] = 5\n",
    "# Have to set the objective to multiclass classification and softmax estimator to do classification\n",
    "param[\"objective\"] = \"multi:softmax\"\n",
    "# Have to also set the number of classes in model. Even though there are only two classes, model only works from 0 to num_classes\n",
    "param[\"num_class\"] = 3\n",
    "\n",
    "# Training model\n",
    "# Setting the number of training rounds\n",
    "num_rounds = 10\n",
    "\n",
    "model = xgb.train(params=param, dtrain=dtrain, num_boost_round=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "shj4kSw8fP-n"
   },
   "outputs": [],
   "source": [
    "#Predict the \"Channel\" values of the test set using the model that we just created. - 1 point\n",
    "y_predict = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BL0_-K71fShz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy percentage:  87.5\n"
     ]
    }
   ],
   "source": [
    "#Get the accuracy of the model that we have trained for the test dataset. - 1 point\n",
    "import numpy as np\n",
    "\n",
    "y_pred = y_predict.astype(int)\n",
    "y_true = np.array(y_test)\n",
    "\n",
    "true = np.sum(y_true == y_pred)\n",
    "accuracy = (true / y_true.size) * 100\n",
    "print(\"Model accuracy percentage: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOqL4BHwoUesuYpNcxAfEJd",
   "collapsed_sections": [],
   "name": "XGBoost.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
